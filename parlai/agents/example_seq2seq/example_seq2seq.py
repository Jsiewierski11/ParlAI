#!/usr/bin/env python3

# Copyright (c) Facebook, Inc. and its affiliates.
# This source code is licensed under the MIT license found in the
# LICENSE file in the root directory of this source tree.
"""
Example sequence to sequence agent for ParlAI.

This contains the minimum boiler plate to implement a seq2seq model using the
TorchAgent API. It can be trained with:

.. code-block::

    python examples/train_model.py -t convai2 -bs 32 -m example_seq2seq -veps 1 -mf /tmp/exseq -vmt f1

"""

from parlai.core.torch_agent import TorchAgent, Output

import torch
import torch.nn as nn
import torch.nn.functional as F


class EncoderRNN(nn.Module):
    """Encodes the input context."""

    def __init__(
        self, vocab_size: int, embedding_size: int, hidden_size: int, numlayers: int
    ):
        """
        Initialize encoder.

        :param input_size:
            size of embedding
        :param hidden_size:
            size of GRU hidden layers
        :param numlayers:
            number of GRU layers
        """
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_size)
        self.gru = nn.GRU(
            embedding_size, hidden_size, num_layers=numlayers, batch_first=True
        )

    def forward(self, input, hidden=None):
        """
        Return encoded state.

        :param input:
            (batchsize x seqlen) tensor of token indices.
        :param hidden:
            optional past hidden state
        """
        embedded = self.embedding(input)
        output, hidden = self.gru(embedded, hidden)
        return output, hidden


class DecoderRNN(nn.Module):
    """Generates a sequence of tokens in response to context."""

    def __init__(
        self, vocab_size: int, embedding_size: int, hidden_size: int, numlayers: int
    ):
        """
        Initialize decoder.

        :param input_size:
            size of embedding
        :param hidden_size:
            size of GRU hidden layers
        :param numlayers:
            number of GRU layers
        """
        super().__init__()
        self.embedding = nn.Embedding(vocab_size, embedding_size)
        self.gru = nn.GRU(
            embedding_size, hidden_size, num_layers=numlayers, batch_first=True
        )
        self.out = nn.Linear(hidden_size, vocab_size)

    def forward(self, input, hidden):
        """
        Return decoder state.

        :param input: batch_size x 1 tensor of token indices.
        :param hidden: past (e.g. encoder) hidden state
        """
        emb = self.embedding(input)
        rel = F.relu(emb)
        output, hidden = self.gru(rel, hidden)
        logits = self.out(output)
        return logits, hidden


class ExampleSeq2seqModel(nn.Module):
    """Joint model."""

    def __init__(self, vocab_size, embedding_size, hidden_size, numlayers):
        super().__init__()
        self.encoder = EncoderRNN(vocab_size, embedding_size, hidden_size, numlayers)
        self.decoder = DecoderRNN(vocab_size, embedding_size, hidden_size, numlayers)

    def forward(self, xs, ys):
        """Forward pass."""
        _encoder_output, encoder_hidden = self.encoder(xs)
        # Teacher forcing: Feed the target as the next input
        decoder_output, decoder_hidden = self.decoder(ys, encoder_hidden)
        return decoder_output


class ExampleSeq2seqAgent(TorchAgent):
    """
    Agent which takes an input sequence and produces an output sequence.

    This model is based on Sean Robertson's `seq2seq tutorial
    <http://pytorch.org/tutorials/intermediate/seq2seq_translation_tutorial.html>`_.
    """

    @classmethod
    def add_cmdline_args(cls, argparser):
        """Add command-line arguments specifically for this agent."""
        super(ExampleSeq2seqAgent, cls).add_cmdline_args(argparser)
        agent = argparser.add_argument_group('ExampleSeq2Seq Arguments')
        agent.add_argument(
            '-hid',
            '--hidden-size',
            type=int,
            default=256,
            help='size of the hidden layers',
        )
        agent.add_argument(
            '-esz',
            '--embedding-size',
            type=int,
            default=128,
            help='size of the token embeddings',
        )
        agent.add_argument(
            '-nl', '--numlayers', type=int, default=2, help='number of hidden layers'
        )
        return agent

    def __init__(self, opt, shared=None):
        """
        Initialize example seq2seq agent.

        :param opt:
            options dict generated by parlai.core.params:ParlaiParser
        :param shared:
            optional shared dict with preinitialized model params
        """
        super().__init__(opt, shared)

        if opt.get('numthreads', 1) > 1:
            raise ValueError("Tutorial agent doesn't support hogwild.")

        if shared is None:
            # always create the model in build_model
            self.model = self.build_model()

            if self.use_cuda:  # set in parent class
                self.model.cuda()

            init_model, is_finetune = self._get_init_model(opt, shared)
            if init_model is not None:
                # load model parameters if available
                print('[ Loading existing model params from {} ]' ''.format(init_model))
                states = self.load(init_model)
            else:
                states = {}

            # initialize the optimizer
            self.init_optim(
                self.model.parameters(),
                states.get('optimizer'),
                states.get('optimizer_type'),
            )
            self.build_lr_scheduler(states, hard_reset=is_finetune)

        else:
            # copy initialized data from shared table
            self.model = shared['model']

        self.reset()

    def build_model(self):
        """Build the model."""
        return ExampleSeq2seqModel(
            len(self.dict),
            self.opt['embedding_size'],
            self.opt['hidden_size'],
            self.opt['numlayers'],
        )

    def train_step(self, batch):
        """
        Train model to produce ys given xs.

        :param batch:
            parlai.core.torch_agent.Batch, contains tensorized version of
            observations.

        :return:
            estimated responses, with teacher forcing on the input sequence.
        """
        xs, ys = batch.text_vec, batch.label_vec
        self.model.train()
        self.zero_grad()

        decoder_output = self.model(xs, ys)
        # autoregressive predictions, so the output at timestep 0 should predict
        # the token at timestep 1
        labels = ys[:, 1:]
        scores = decoder_output[:, :-1]
        loss = F.cross_entropy(
            scores.reshape(-1, scores.size(-1)),
            labels.reshape(-1),
            ignore_index=self.NULL_IDX,  # ignore padding
        )
        self.backward(loss)
        self.update_params()

        _max_score, predictions = decoder_output.max(2)
        return Output([self._v2t(p) for p in predictions])

    def eval_step(self, batch):
        """
        Generate a response to the input tokens.

        :param batch:
            parlai.core.torch_agent.Batch, contains tensorized version of
            observations.

        :return:
            predicted responses (list of Output objects).
        """
        # at test time, we need to do perform search, since we can't use teacher-forcing
        xs = batch.text_vec
        self.model.eval()
        # go ahead and encode the context once
        _, encoder_hidden = self.model.encoder(xs)

        # initialize with the start token
        ys = torch.zeros((xs.size(0), 1), dtype=torch.long).fill_(self.START_IDX)
        # move to the same device as the model
        ys = ys.to(xs.device)

        # in this tutorial, we always decode a fixed number of tokens
        for _ in range(32):
            # generate at most longest_label tokens
            decoder_output, decoder_hidden = self.model.decoder(ys, encoder_hidden)
            chosen = decoder_output[:, -1].argmax(1).unsqueeze(1)
            ys = torch.cat([ys, chosen], dim=1)

        return Output([self._v2t(p) for p in ys])
